\documentclass{article}
\usepackage{fancyref}
\usepackage{todonotes}
\usepackage[utf8]{inputenc}

\usepackage[style=ieee,backend=biber]{biblatex}
\addbibresource{proposal-cites.bib}

\title{Project Proposal \\ Using Agents and Genetic Algorithms to model, analyse and improve strategies for trading on an online auction site with feedback and reputation systems}
\author{Christopher Taylor \\ Department of Computer Science \\ University of Bath \\ me@christophertaylor.net}

\begin{document}
\maketitle
\todo{better title}
\listoftodos
\section{Problem Description}
\label{sec:problem-description}
There are many websites and services that facilitate trade between users, perhaps one of the most well known is eBay. These services can be of great value to users for a wide variety of different purposes, but it can come at a cost - there are malicious users who attempt to defraud and scam users.

The platform has several institutional methods of preventing fraud and reimbursing victims, but the system that most factors into user's decision making is the feedback system. The feedback system gives buyers an opportunity to leave a comment and positive, negative or neutral feedback on a transaction. All of this information is made available to users when they are deciding to carry out a transaction - including a feedback score and the seller's percentage of positive feedback. From this, the potential buyer can decide whether or not they trust the user to not defraud them, and to deliver the goods in a good state, and in good time.\cite{gregg2006role}

I am planning on creating an abstract model of the eBay systems in order to explore some of the strategies users could employ on a service such as eBay. Starting off simply, I will then introduce more factors (\fref{sec:factors-experiment}) into agents' decision making processes - exploring factors in the model and in their wider academic context. Rather than just running each simulation once with a randomly generated set of agents, I will be employing a genetic algorithm (\fref{sec:genetic-algorithms}) in order to refine the strategies and parameters over many generations.

\subsection{The Auction Model}
Each simulation will run as follows:
\begin{itemize}
	\item N agents (representing users) are somehow selected or generated.
	\item The number of transactions for the entire simulation is randomly determined, and hidden from the agents.
	\item That many transactions runs, each one going as follows:
	\begin{itemize}
		\item Two random agents from the list are selected
		\item Each choose whether to Cooperate, Defect or Decline. An agent that chooses to cooperate goes into the transaction with good faith, while an agent that chooses to defect attempts to scam or cheat the other. Each agent also has the choice to decline a transaction. The payoff for these actions is defined in \fref{fig:model-payoff}.
		\item Each user then has the opportunity to leave feedback about the user they traded with (if the transaction actually went ahead - that is, if neither declined it.)
	\end{itemize}
	\item After all the transactions, each agent's score is computed.
\end{itemize}

After this, the results can be analysed and/or a new generation (see \fref{sec:genetic-algorithms}) can be bred for the next round of simulations.
	\begin{figure}[h]
		\begin{center}
			\label{fig:model-payoff}
			\caption{The Payoff Matrix for a transaction}
			\begin{tabular}{| l || c | c | c |}
				\hline
				A1,A2 & A2 Coop & A2 Defe & A2 Decl \\ \hline
				A1 Coop & 2,2 & -2,4 & 0,0 \\ \hline  
				A1 Defe & 4,-2 & -1, -1 & 0,0 \\ \hline
				A1 Decl & 0,0 & 0,0 & 0,0 \\ \hline
			\end{tabular}
		\end{center}
	\end{figure}

\subsubsection{Justification for model}
\label{sec:justification-model}
As previously discussed, this model is very much an abstraction rather than a faithful representation of how a site may work. Things not factored in include:
\begin{itemize}
	\item Modelling of the actual content of transactions: the physical packaging and sending of goods, what the goods actually are, methods of payment and so on.s
	\item Relatedly, this includes different methods of defection - sending wrong/broken goods or not sending anything. Additionally, things such as a transaction falling through without malicious intent are not modelled.\cite{gregg2008typology}
	\item The payoffs for each person are simplified and uniform.
	\item Real users do not choose who to trade with at random.
	\item In the actual eBay system, sellers post an item for sale and buyers choose whether or not to purchase them (taking into account things such as desire for the item and the reputation of the user.) In addition, only buyers are allows to post feedback on sellers. In this model, there is no role for "buyer" or "seller" - just two agents participating in a transaction.
\end{itemize}

Despite these limitations, I believe the model still has value as an analytical tool.

\todo{Expand justification}

\subsubsection{Game Theory Analysis}
\label{sec:game-theory}
Each individual transaction decision is similar to a Prisoner's Dilemma, and as such we can learn from the well-developed thought that surrounds that problem.

The Prisoner's Dilemma is usually explained thusly: two people suspected of committing some crime have been arrested and are being interrogated by the police. The police officer in question doesn't have sufficient evidence to arrest them on the crime they have committed, but can arrest them on a lesser charge. The officer places them in seperate rooms and offers them a deal - they can either stay quiet (cooperate), or confess and incriminate their partner (defect).
\begin{itemize}
	\item If both of the suspects stay quiet, they will both be charged with the lesser offense and given a short prison sentence.
	\item If one of the suspects talks, that suspect walks free while the other suffers a long prison sentence.
	\item However, if both of them talk, neither can reap the benefits from being a witness and both will suffer a long sentence.
\end{itemize}
	\begin{figure}
		\label{fig:generic-prisoners-dilemma}
		\caption{The payoff matrix for a generic prisoner's dilemma}
		\begin{tabular}{| l || c | c | c |}
			\hline
			A1,A2 & A2 Coop & A2 Defe \\ \hline
			A1 Coop & -1,-1 & -7,0 \\ \hline  
			A1 Defe & 0,-7 & -3,-3  \\ \hline
		\end{tabular}
	\end{figure}

A single instance of a Prisoner's Dilemma is a solved problem from a Game Theory perspective - it's Nash Equilibrium is for both players to defect, despite the fact that, if both had cooperated, they would have gotten a shorter sentence.

Repeated games of the Prisoner's Dilemma (known as the \emph{Iterated Prisoner's Dilemma} or IPD) is a more complicated issue - defined as when the same players undertake $n$ number of games, with full memory of all the previous games. While, for a fixed and known $n$, the game has the same nash equilibrium (to always defect) - the repeated nature of the game gives an opportunity for counterplay and changing decisions.

The most simple strategies are a naive \emph{always cooperate} or \emph{always defect} strategy, but there are other - more complicated - strategies, which may or may not produce better results on average. Some of these include:
\begin{description}
	\item[Random] - Chooses an option at random. Sometimes $P(defect) = P(cooperate) = 0.5$, but the probabilites can theoretically be anything.
	\item[Tit for Tat] - Cooperate in the first round, then repeat the opponent's move every round after that. (I.E. defect against an opponent who defected last round.)
	\item[Tit for Two Tat] - Cooperate unless the opponent defects twice in a row, then defect
	\item[Grim Trigger] - Cooperate until opponent defects, then defect forever.
	\item[Probing] - A cooperative strategy (such as Tit for Tat), except it occasionally randomly defects, to see what the opponent does.
\end{description}

Strategies can also take elements and pieces from other strategies, to create even more complicated strategies. The strategies that will be used in the main problem will draw elements from the deep analysis of the IPD, but will have to take into account the number of ways that the problem differs from the IPD.

\begin{description}
	\item[Decline] - Unlike in the standard IPD, agents can choose to decline a transaction with an agent for no cost/payoff if they believe it is in their best interest.
	\item[Lots of agents] - The standard IPD is played with two agents over a large number of games. In this problem, a large number of agents are playing, and agents will trade with a large number of other agents. Strategies differ in large, evolving populations than from two-player games.\cite{stewart2013extortion} \footnote{The archetypal prisoner's dilemma-esque problem in a large population is the Hawk-Dove game, which will be covered and discussed in the dissertation itself.}
	\item[Unreliable history] - Instead of having an accurate history of your transaction history with an agent, an agent has to rely on the (possibly unreliable) feedback and reputation history left by other agents that agent has transacted with.
\end{description}

\subsubsection{Psychology and Sociology of cooperation}
\label{sec:psychology-sociology-cooperation}
While game theory is a field with great explanatory power, human behaviour alone can not be explained by mathematical calculation - humans often exhibit behaviour that is often contradicts a purely calculating model. Humans cooperate, they trust one another, they exhibit alturism\cite{fehr2003nature}, they act with a sense of fairness\cite{forsythe1994fairness}, and so on.

In \cite{Schneier2012}, Schneier suggests a taxonomy of external pressures that influence people's decision making: moral pressures, reputational pressures, institutional pressures and security systems. Each of these influence people's decisions in a complicated and occasionally opposing manner. He writes\cite[p63]{Schneier2012}:

\begin{quotation}
Prisoner's Dilemmas involve a risk trade-off between group interest and self-interest, but it's generally only a dilemma if you look at it very narrowly. For most people, most of the time, there's no actual dilemma. We don't stand at the checkout line at a store thinking: "Either the merchant is selling me a big screen TV, or this box is secretly filled with rocks. If it's rocks, I'm better off giving him counterfeit money. And if it has a TV, I'm still better off giving him counterfeit money." Generally, we just pay for the TV, put it in our car, and drive home.
\end{quotation}

With a purely rational, purely calculative, maximising of self-interest approach - the trust required for the everyday tasks of civilisation (such as buying something in a shop), and civilisation itself, breaks down. It is lucky, then, that most people do not take this approach - we, as humans, have a wide range of conflicting motivations and pressures that influence our decisions.

Relating this back to the auction service problem: this means that the majority of users won't be out to scam others. In \cite{gregg2008typology}, the rate of accusations of fraud is 0.2\%, with official eBay estimates at 0.01\%. The true value being difficult to ascertain due to the difficulty in establishing the validity of a large number of claims, but it is obvious that the vast majority of transactions are \emph{not} fraudulent. This is obviously a positive thing for the platform, as too high a chance of being defrauded is likely to drive people away.

In terms of our agents, it means that the majority of the agents at the start of the scenarios will be genuine users with only a few malicious agents. They will be described using terms of the "Hawk-Dove game" \cite{smith1973lhe}, a prisoner's dilemma-like game on a population level. The agent types are:
\begin{description}
	\item[Dove] - Genuine user, wishes to cooperate and engage in mutually beneficial transactions - maximising its utility while still remaining honest. The dove will not defect, but will decline transactions if it sees fit.
	\item[Hawk] - Malicious user, wishes to maximise their own utility at the expense of others. The hawk can defect, cooperate or decline as it believes is best.
\end{description}

Within the dove and hawk categories, there will be differences in the strategies employed by each individual agent - but the spirit of the agent's goal will stay the same.

\subsection{Genetic Algorithms}
\label{sec:genetic-algorithms}
\todo{Genetic Algorithms: what they are, why I'm using them.}

\subsection{Feedback and Reputation systems}
\label{sec:reputation-systems}
\todo{Reputation Systems}

\subsection{Factors to experiment with}
\label{sec:factors-experiment}
\todo{Factors for Experiment}

\section{Requirements}
\label{sec:requirements}
\todo{Requirements.}

\section{Project Plan}
\label{sec:project-plan}
\todo{Project Plan}

\printbibliography

\end{document}
